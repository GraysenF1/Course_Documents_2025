---
title: "Data Import & Tidy Tutorial I"
author: "Douglas A. Campbell, Brian Beardsall"
date: "`r format(Sys.Date())`"
output:
  html_document:
    df_print: paged
    keep_md: true
---
## Introduction
Data is courtesy of Nerissa Fisher, UTS Australia

This tutorial introduces semi-interactive import and tidying of data in R, following tidyverse principles of R for Data Science
  https://r4ds.had.co.nz/

Tidying data involves standardizing variable names, changing data types, filtering, merging and rearranging data to prepare for analyses or presentation.

As your tidying skills grow you will cope with more complex, less tidied data.  
Data import and tidying through scripts maintains a record of actions, which can later be re-run, audited or modified, an important part of 'OpenData' and 'OpenPublication'.

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook, residing within a directory with a .Rproj file, and a .git, connected to a GitHub repository, https://github.com/MtADATA3101/ScriptedDataImport.

After significant edits we 'Commit' with a message, then 'Push' the edited version to GitHub.

Follow instructions in
https://happygitwithr.com/

to generate a local cloned repository.

When you execute code chunks by clicking a green arrow, or an option from the 'Run' pull down menu, the results appear beneath the code chunk.

Text outside chunks is not run in R.
Add new chunks by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you 'knit' the notebook, a .md markdown file and an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

## Load Libraries
Libraries (or 'packages') contain additions to base R.
```{r load libraries}
#set of packages for data wrangling and plotting
library(tidyverse)

#assists with date formats
library(lubridate)

```

## Project Variables
Assign project-specific values to the variables 'Project', 'DataIn', 'PlotsPath', and 'ProcessData'.
Then we can use these variables in subsequent code chunks to construct file paths.
```{r set project path variables}
Project <- "DataTidyTutorial"
DataIn <- "DataIn"
PlotsPath <- "Plots"
ProcessData <- "ProcessData"
```

## Import a data object previously stored as .Rds object, or as a .csv object

Even though we import from two different file formats, the resulting data objects are identical.
```{r read Rds}
DataRDS <- readRDS(file = file.path(ProcessData, "DataImportTutorialData.Rds", fsep =.Platform$file.sep))

DataCSV <- read_delim(file = file.path(ProcessData, "DataImportTutorialData.csv", fsep =.Platform$file.sep), delim = Delimiter, comment = Comment, skip = HeaderRows)
```

## Look at Column Names to check for non-standard names  
```{r column names}
colnames(DataRDS)
```
Variable naming involves 3 general criteria:
1. Consistent; 1 name for 1 variable
2. Legible; variable name should be informative to a reader as to the data content of the variable
3. Concise; variable name should be short and easy to type.

These three criteria may conflict.
Consistent is definitely the top priority.
More legible & verbose names may take priority over conciseness.

To these 3 general criteria, for R we have an additional consideration of 'syntatic' vs. 'non-syntactic' variable names.
Syntatic variable names include only letters, numerals and "_", and do not start with numerals.

Note the many non-standard characters in the column names for DataRDS (which are now 'variable names'):
space, ', /, -, (, ), [, ], 째
These characters may, or may not, cause problems later in R.
One way forward is to replace all of them.
"[[:punct:]]" is a REGEX expression for all punctuation characters, which include all our problematic characters.
There are two approaches below; in both cases we create an object (character vector, newcolnames; or dataframe df_newcolnames), by taking the colnames of the DataRDS object and replacing "[[:punct:]]" with with "", nothing.
Then we remove all " " spaces.
Then we remove the "째".

```{r create newcolnames}
#alternate approach
# newcolnames <- str_replace_all(colnames(DataRDS), "[[:punct:]]", "") %>%
#   str_replace_all(" ", "") %>% 
#   str_replace_all("째", "")
# newcolnames


#https://cmdlinetips.com/2022/03/how-to-replace-multiple-column-names-of-a-dataframe-with-tidyverse/
df_newcolnames <- tibble(
  "new_name" = str_replace_all(colnames(DataRDS), "[[:punct:]]", "") %>%
  str_replace_all(" ", "") %>% 
  str_replace_all("째", ""),
  "old_name" = colnames(DataRDS)
)

#convert dataframe to a vector of named values; deframe() function uses first column as name and the second column as value.
newcolnames <- deframe(df_newcolnames)
```

Then we rename the dataframe columns, creating the new data object TidyData while we do it.
```{r rename columns}
#Doug does not completely understand this alternate code... but it works, Google knows all
# TidyData <- DataRDS %>% 
#   `colnames<-`(newcolnames)
# 
# colnames(TidyData)

#https://cmdlinetips.com/2022/03/how-to-replace-multiple-column-names-of-a-dataframe-with-tidyverse/

TidyData <- DataRDS %>%
  rename(!!! newcolnames)

colnames(TidyData)
```

In general, we avoid removing columns from imported data.
But some variable values also contain punctuation characters.
We cannot use replace all "[[:punct:]]" because that would remove "." decimal place in the tibble (dataframe)
Instead in this case we remove the problematic characters by removing:
-'Code' column which is now redundant with 'Lincomycin' and 'Treatmentmin';
-'GPS', X41, X42, X43 columns which are meaningless because our instrument did not have GPS enabled

This step is a bit reckless, because I am assigning the variable name 'TidyData' to a new, modified data object.
The previous 'TidyData' object is thus lost.
This limits the number of extraneous, intermediate data objects in the Global Environment, but it makes auditing harder if things go wrong.
When starting out it can be safer to create a new data object at each step, so you can easily compare to see if the changes are what you intended at each step
```{r variable tidy}
TidyData <- TidyData %>% 
  select(-c("Code", "GPS", "X41", "X42", "X43"))

#safer initial version with new data object for comparison with TidyData
# TidyData2 <- TidyData %>% 
#   select(-c("Code", "GPS", "X41", "X42", "X43"))
```

We see the 'Date' column includes date information, but it is formatted as class 'character' column.
The 'CDateTime' contains the date and time the file was created; not necessarily the same as the date the experiment was actually performed.
'ymd' and 'ymd_hms' are functions from the 'lubridate' package.
Note it is again risky to overwrite existing variable names with newly formatted content, but the alternative means a proliferation of extra data columns.
The choice depends upon whether there is any need for the original, as well as the reformatted, variable column.

```{r fix dates}
TidyData <- TidyData %>%
  mutate(Date = lubridate::ymd(Date),
         CDateTime = lubridate::ymd_hms(CDateTime))
```

Some of the rows are 'empty', which I can tell from missing or nonsensical data.
We can remove them by filtering out all rows where the value of a given known variable = NA

```{r filter TidyData} 
TidyData <- TidyData %>%
  filter(!is.na(Treatmentmin))
```


```{r TidyData preview}
TidyData[1:10]
```

Sometimes during initial import the read function cannot unambiguously determine the class of the data in a column (variable), sometimes because of missing values, or rows with different classes of data.
Species & Filename are columnswe want to remain as character class.
Most other columns should be numeric.
If the variable class is incorrect, we can convert numeral character columns to numeric.
There are many functions to convert variables from one class to a different class (character to numeric, numeric to logical, character to factor...)
```{r fix numerics}
TidyData <- TidyData %>%
  mutate_at(colnames(TidyData)[4:40],  as.numeric)

#smarter alternative:
#Use type_convert from readr (in the 'tidyverse' package) to re-parse all column types
#TidyDataAlt<- readr::type_convert(TidyData)
```

## Quick plot for reality therapy; does the data show what we expect?
We often have ideas about the data; quick plots can help check whether the imported data is behaving as expected.
Watch for messages after the plots; missing points can indicate issues with the data structure.
```{r reality therapy plots}
TidyData %>%
  ggplot() +
  geom_point(aes(x = Treatmentmin, y = Sigma)) +
  theme_bw()

TidyData %>%
  ggplot() +
  geom_point(aes(x = Treatmentmin, y = FvFmFqFm)) +
  geom_line(aes(x = Treatmentmin, y = FvFmFqFm)) +
  facet_grid(rows = vars(Lincomycin), cols = vars(Species)) + 
  theme_bw()
```


## Save the tidied data for further analyses
.Rds is an internal R data format for rapid re-import into other RNotebooks or scripts.
.csv is a generic comma separated values format; be very careful about moving .csv through multiple software because different spreadsheet software may make different guesses as to the content of columns; Excel is notorious.
```{r save TidyData}
saveRDS(TidyData, file = file.path(ProcessData,paste(Project, "TidyData", ".Rds",sep = ""),fsep = .Platform$file.sep))

write_csv(TidyData, file = file.path(ProcessData,paste(Project, "TidyData",".csv",sep = ""),fsep = .Platform$file.sep))
```


## Workflow Ideas
Here, we construct a file name by pasting together the value of the 'Project' variable with some text:
```{r construct filename}
paste(Project, "TidyData", ".Rds",sep = "")
```

Then, we add a file path to put the file in a sub-folder, rather than in the top directory for the project.
```{r construct filepath}
file.path(ProcessData,paste(Project, "TidyData", ".Rds",sep = ""),fsep = .Platform$file.sep)
```
Note the 'fsep = .Platform$file.sep'. This tells 'file.path' to construct a filepath using the appropriate file path separator for whatever platform is running the script ("/" for Mac, "\" for Windows, other options for other platforms).

Then we save the contents of the data object TidyData to the file defined by the file.path
```{r resave TidyData}
saveRDS(TidyData, file = file.path(ProcessData,paste(Project, "TidyData", ".Rds",sep = ""),fsep = .Platform$file.sep))
```


Did we need to do this in many steps, or create many intermediate data structures?  
No.  
But long strings of %>% or |> piping are hard to follow and to debug when starting from scratch.
```{r all at once}
TidyData2 <- readRDS(file = file.path(ProcessData, "DataImportTutorialData.Rds"))

newcolnames2 <- str_replace_all(colnames(TidyData2), "[[:punct:]]", "") %>%
  str_replace_all(" ", "") %>%
  str_replace_all("째", "")

TidyData2 <- TidyData2 %>% 
  `colnames<-`(newcolnames2) %>%
  select(-c("Code", "GPS", "X41", "X42", "X43")) %>% 
  mutate(Date = ymd(Date),
         CDateTime = ymd_hms(CDateTime))  %>%
  filter(!is.na(Treatmentmin))  %>%
  type_convert()
```

